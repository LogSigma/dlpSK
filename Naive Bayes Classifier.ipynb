{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 베이즈 정리를 이용한 가장 간단한 supervised classifier.\n",
    "* 모든 feature의 결합확률분포를 구하기가 힘든것을 감안하여, 모든 feature가 서로 독립임을 가정하여 사용함.(그래서 naive 라는 말이 붙음)\n",
    "* 간단한것에 비해 성능은 좋지만, 한계도 많다.\n",
    "* 실제 데이터는 대부분 feature 사이에 correlation이 존재하기 때문에, 실제로는 많이 사용하지 못한다. 예전에는 sentiment analysis나 spam filtering에 많이 사용했었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![토픽 모델링의 예](figs/example1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![토픽 모델링의 예](figs/example2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [('i like you', 'pos'), \n",
    "         ('i hate you', 'neg'), \n",
    "         ('you like me', 'neg'),\n",
    "         ('i like her', 'pos')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hate', 'her', 'i', 'like', 'me', 'you'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = set(word.lower() for sentence in train for word in word_tokenize(sentence[0]))\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'i': True,\n",
       "   'me': False,\n",
       "   'her': False,\n",
       "   'hate': False,\n",
       "   'like': True,\n",
       "   'you': True},\n",
       "  'pos'),\n",
       " ({'i': True,\n",
       "   'me': False,\n",
       "   'her': False,\n",
       "   'hate': True,\n",
       "   'like': False,\n",
       "   'you': True},\n",
       "  'neg'),\n",
       " ({'i': False,\n",
       "   'me': True,\n",
       "   'her': False,\n",
       "   'hate': False,\n",
       "   'like': True,\n",
       "   'you': True},\n",
       "  'neg'),\n",
       " ({'i': True,\n",
       "   'me': False,\n",
       "   'her': True,\n",
       "   'hate': False,\n",
       "   'like': True,\n",
       "   'you': False},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1]) for x in train]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    like = True              pos : neg    =      1.7 : 1.0\n",
      "                    hate = False             pos : neg    =      1.7 : 1.0\n",
      "                     her = False             neg : pos    =      1.7 : 1.0\n",
      "                      me = False             pos : neg    =      1.7 : 1.0\n",
      "                       i = True              pos : neg    =      1.7 : 1.0\n",
      "                     you = True              neg : pos    =      1.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(t)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': True,\n",
       " 'me': False,\n",
       " 'her': False,\n",
       " 'hate': False,\n",
       " 'like': True,\n",
       " 'you': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = 'i like MeRui'\n",
    "test_sent_features = {word.lower(): (word in word_tokenize(test_sentence.lower())) for word in all_words}\n",
    "test_sent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(test_sent_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Korean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emphymacbook/anaconda3/envs/text_analysis/lib/python3.6/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "pos_tagger = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [('메리가 좋아', 'pos'), \n",
    "         ('고양이도 좋아', 'pos'),\n",
    "         ('난 수업이 지루해', 'neg'),\n",
    "         ('메리는 이쁜 고양이야', 'pos'),\n",
    "         ('난 마치고 메리랑 놀거야', 'pos')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'고양이도',\n",
       " '고양이야',\n",
       " '난',\n",
       " '놀거야',\n",
       " '마치고',\n",
       " '메리가',\n",
       " '메리는',\n",
       " '메리랑',\n",
       " '수업이',\n",
       " '이쁜',\n",
       " '좋아',\n",
       " '지루해'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = set(word.lower() for sentence in train for word in word_tokenize(sentence[0]))\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'메리가': True,\n",
       "   '난': False,\n",
       "   '마치고': False,\n",
       "   '놀거야': False,\n",
       "   '수업이': False,\n",
       "   '메리랑': False,\n",
       "   '지루해': False,\n",
       "   '메리는': False,\n",
       "   '좋아': True,\n",
       "   '고양이야': False,\n",
       "   '고양이도': False,\n",
       "   '이쁜': False},\n",
       "  'pos'),\n",
       " ({'메리가': False,\n",
       "   '난': False,\n",
       "   '마치고': False,\n",
       "   '놀거야': False,\n",
       "   '수업이': False,\n",
       "   '메리랑': False,\n",
       "   '지루해': False,\n",
       "   '메리는': False,\n",
       "   '좋아': True,\n",
       "   '고양이야': False,\n",
       "   '고양이도': True,\n",
       "   '이쁜': False},\n",
       "  'pos'),\n",
       " ({'메리가': False,\n",
       "   '난': True,\n",
       "   '마치고': False,\n",
       "   '놀거야': False,\n",
       "   '수업이': True,\n",
       "   '메리랑': False,\n",
       "   '지루해': True,\n",
       "   '메리는': False,\n",
       "   '좋아': False,\n",
       "   '고양이야': False,\n",
       "   '고양이도': False,\n",
       "   '이쁜': False},\n",
       "  'neg'),\n",
       " ({'메리가': False,\n",
       "   '난': False,\n",
       "   '마치고': False,\n",
       "   '놀거야': False,\n",
       "   '수업이': False,\n",
       "   '메리랑': False,\n",
       "   '지루해': False,\n",
       "   '메리는': True,\n",
       "   '좋아': False,\n",
       "   '고양이야': True,\n",
       "   '고양이도': False,\n",
       "   '이쁜': True},\n",
       "  'pos'),\n",
       " ({'메리가': False,\n",
       "   '난': True,\n",
       "   '마치고': True,\n",
       "   '놀거야': True,\n",
       "   '수업이': False,\n",
       "   '메리랑': True,\n",
       "   '지루해': False,\n",
       "   '메리는': False,\n",
       "   '좋아': False,\n",
       "   '고양이야': False,\n",
       "   '고양이도': False,\n",
       "   '이쁜': False},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1]) for x in train]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                       난 = True              neg : pos    =      2.5 : 1.0\n",
      "                      좋아 = False             neg : pos    =      1.5 : 1.0\n",
      "                     마치고 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리는 = False             neg : pos    =      1.1 : 1.0\n",
      "                     놀거야 = False             neg : pos    =      1.1 : 1.0\n",
      "                    고양이도 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리가 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리랑 = False             neg : pos    =      1.1 : 1.0\n",
      "                      이쁜 = False             neg : pos    =      1.1 : 1.0\n",
      "                    고양이야 = False             neg : pos    =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(t)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = '난 수업이 마치면 메리랑 놀거야'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'메리가': False,\n",
       " '난': True,\n",
       " '마치고': False,\n",
       " '놀거야': True,\n",
       " '수업이': True,\n",
       " '메리랑': True,\n",
       " '지루해': False,\n",
       " '메리는': False,\n",
       " '좋아': False,\n",
       " '고양이야': False,\n",
       " '고양이도': False,\n",
       " '이쁜': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent_features = {word.lower(): (word in word_tokenize(test_sentence.lower())) for word in all_words}\n",
    "test_sent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(test_sent_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['메리/Noun', '가/Josa', '좋다/Adjective'], 'pos'),\n",
       " (['고양이/Noun', '도/Josa', '좋다/Adjective'], 'pos'),\n",
       " (['난/Noun', '수업/Noun', '이/Josa', '지루하다/Adjective'], 'neg'),\n",
       " (['메리/Noun', '는/Josa', '이쁘다/Adjective', '고양이/Noun', '야/Josa'], 'pos'),\n",
       " (['난/Noun', '마치/Noun', '고/Josa', '메리/Noun', '랑/Josa', '놀다/Verb'], 'pos')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_docs = [(tokenize(row[0]), row[1]) for row in train]\n",
    "train_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['메리/Noun',\n",
       " '가/Josa',\n",
       " '좋다/Adjective',\n",
       " '고양이/Noun',\n",
       " '도/Josa',\n",
       " '좋다/Adjective',\n",
       " '난/Noun',\n",
       " '수업/Noun',\n",
       " '이/Josa',\n",
       " '지루하다/Adjective',\n",
       " '메리/Noun',\n",
       " '는/Josa',\n",
       " '이쁘다/Adjective',\n",
       " '고양이/Noun',\n",
       " '야/Josa',\n",
       " '난/Noun',\n",
       " '마치/Noun',\n",
       " '고/Josa',\n",
       " '메리/Noun',\n",
       " '랑/Josa',\n",
       " '놀다/Verb']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [t for d in train_docs for t in d[0]]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_exists(doc):\n",
    "    return {word: (word in set(doc)) for word in tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'메리/Noun': True,\n",
       "   '가/Josa': True,\n",
       "   '좋다/Adjective': True,\n",
       "   '고양이/Noun': False,\n",
       "   '도/Josa': False,\n",
       "   '난/Noun': False,\n",
       "   '수업/Noun': False,\n",
       "   '이/Josa': False,\n",
       "   '지루하다/Adjective': False,\n",
       "   '는/Josa': False,\n",
       "   '이쁘다/Adjective': False,\n",
       "   '야/Josa': False,\n",
       "   '마치/Noun': False,\n",
       "   '고/Josa': False,\n",
       "   '랑/Josa': False,\n",
       "   '놀다/Verb': False},\n",
       "  'pos'),\n",
       " ({'메리/Noun': False,\n",
       "   '가/Josa': False,\n",
       "   '좋다/Adjective': True,\n",
       "   '고양이/Noun': True,\n",
       "   '도/Josa': True,\n",
       "   '난/Noun': False,\n",
       "   '수업/Noun': False,\n",
       "   '이/Josa': False,\n",
       "   '지루하다/Adjective': False,\n",
       "   '는/Josa': False,\n",
       "   '이쁘다/Adjective': False,\n",
       "   '야/Josa': False,\n",
       "   '마치/Noun': False,\n",
       "   '고/Josa': False,\n",
       "   '랑/Josa': False,\n",
       "   '놀다/Verb': False},\n",
       "  'pos'),\n",
       " ({'메리/Noun': False,\n",
       "   '가/Josa': False,\n",
       "   '좋다/Adjective': False,\n",
       "   '고양이/Noun': False,\n",
       "   '도/Josa': False,\n",
       "   '난/Noun': True,\n",
       "   '수업/Noun': True,\n",
       "   '이/Josa': True,\n",
       "   '지루하다/Adjective': True,\n",
       "   '는/Josa': False,\n",
       "   '이쁘다/Adjective': False,\n",
       "   '야/Josa': False,\n",
       "   '마치/Noun': False,\n",
       "   '고/Josa': False,\n",
       "   '랑/Josa': False,\n",
       "   '놀다/Verb': False},\n",
       "  'neg'),\n",
       " ({'메리/Noun': True,\n",
       "   '가/Josa': False,\n",
       "   '좋다/Adjective': False,\n",
       "   '고양이/Noun': True,\n",
       "   '도/Josa': False,\n",
       "   '난/Noun': False,\n",
       "   '수업/Noun': False,\n",
       "   '이/Josa': False,\n",
       "   '지루하다/Adjective': False,\n",
       "   '는/Josa': True,\n",
       "   '이쁘다/Adjective': True,\n",
       "   '야/Josa': True,\n",
       "   '마치/Noun': False,\n",
       "   '고/Josa': False,\n",
       "   '랑/Josa': False,\n",
       "   '놀다/Verb': False},\n",
       "  'pos'),\n",
       " ({'메리/Noun': True,\n",
       "   '가/Josa': False,\n",
       "   '좋다/Adjective': False,\n",
       "   '고양이/Noun': False,\n",
       "   '도/Josa': False,\n",
       "   '난/Noun': True,\n",
       "   '수업/Noun': False,\n",
       "   '이/Josa': False,\n",
       "   '지루하다/Adjective': False,\n",
       "   '는/Josa': False,\n",
       "   '이쁘다/Adjective': False,\n",
       "   '야/Josa': False,\n",
       "   '마치/Noun': True,\n",
       "   '고/Josa': True,\n",
       "   '랑/Josa': True,\n",
       "   '놀다/Verb': True},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xy = [(term_exists(d), c) for d,c in train_docs]\n",
    "train_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = [(\"난 수업이 마치면 메리랑 놀거야\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('난', 'Noun'),\n",
       " ('수업', 'Noun'),\n",
       " ('이', 'Josa'),\n",
       " ('마치', 'Noun'),\n",
       " ('면', 'Josa'),\n",
       " ('메리', 'Noun'),\n",
       " ('랑', 'Josa'),\n",
       " ('놀거야', 'Verb')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_docs = pos_tagger.pos(test_sentence[0])\n",
    "test_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  난/Noun = True              neg : pos    =      2.5 : 1.0\n",
      "                 메리/Noun = False             neg : pos    =      2.5 : 1.0\n",
      "            좋다/Adjective = False             neg : pos    =      1.5 : 1.0\n",
      "                고양이/Noun = False             neg : pos    =      1.5 : 1.0\n",
      "                  도/Josa = False             neg : pos    =      1.1 : 1.0\n",
      "                  는/Josa = False             neg : pos    =      1.1 : 1.0\n",
      "                  고/Josa = False             neg : pos    =      1.1 : 1.0\n",
      "                 놀다/Verb = False             neg : pos    =      1.1 : 1.0\n",
      "                  가/Josa = False             neg : pos    =      1.1 : 1.0\n",
      "                 마치/Noun = False             neg : pos    =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('난', 'Noun'): False,\n",
       " ('수업', 'Noun'): False,\n",
       " ('이', 'Josa'): False,\n",
       " ('마치', 'Noun'): False,\n",
       " ('면', 'Josa'): False,\n",
       " ('메리', 'Noun'): False,\n",
       " ('랑', 'Josa'): False,\n",
       " ('놀거야', 'Verb'): False}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent_features = {word: (word in tokens) for word in test_docs}\n",
    "test_sent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(test_sent_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "news = fetch_20newsgroups(subset=\"all\")\n",
    "X = news.data\n",
    "y = news.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model1 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('model', MultinomialNB()),\n",
    "])\n",
    "model2 = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('model', MultinomialNB()),\n",
    "])\n",
    "model3 = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words=\"english\")),\n",
    "    ('model', MultinomialNB()),\n",
    "])\n",
    "model4 = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words=\"english\",\n",
    "                             token_pattern=r\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\")),\n",
    "    ('model', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1: Mean score: 0.855\n",
      "Model2: Mean score: 0.856\n",
      "Model3: Mean score: 0.883\n",
      "Model4: Mean score: 0.888\n",
      "CPU times: user 1min 26s, sys: 2.95 s, total: 1min 29s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "for i, model in enumerate([model1, model2, model3, model4]):\n",
    "    scores = cross_val_score(model, X, y, cv=5)\n",
    "    print((\"Model{0:d}: Mean score: {1:.3f}\").format(i + 1, np.mean(scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
